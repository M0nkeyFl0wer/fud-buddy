{
  "name": "fud-buddy-ai-server",
  "version": "1.0.0",
  "description": "Local AI service for FUD Buddy using Ollama",
  "main": "server.js",
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js",
    "test": "echo \"No tests yet\" && exit 0"
  },
  "dependencies": {
    "express": "^4.18.2",
    "cors": "^2.8.5",
    "express-rate-limit": "^7.1.5",
    "http-proxy-middleware": "^2.0.6"
  },
  "devDependencies": {
    "nodemon": "^3.0.2"
  },
  "engines": {
    "node": ">=16.0.0"
  },
  "keywords": [
    "ai",
    "ollama",
    "food",
    "recommendations",
    "local-llm"
  ],
  "author": "FUD Buddy Team",
  "license": "MIT"
}